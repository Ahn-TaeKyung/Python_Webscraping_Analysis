# streamlit run streamlit_submit.py
import streamlit as st
import requests
import bs4
import re
import pandas as pd
import json
import numpy as np
from bs4 import BeautifulSoup

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‚¬ëŒì¸ ì±„ìš© ì •ë³´ í¬ë¡¤ëŸ¬",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# local_css("style.css")  # ë¡œì»¬ CSS íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚¬ìš©

# JSON íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_json_data():
    file_path = 'data/'
    with open(file_path + 'PREFIX.json', 'r', encoding='utf-8') as f:
        PREFIX = json.load(f)
    with open(file_path + 'SUFFIX.json', 'r', encoding='utf-8') as f:
        SUFFIX = json.load(f)
    return PREFIX, SUFFIX

# ë°ì´í„° íŒŒì‹± í•¨ìˆ˜
@st.cache_data
def parse_data(PREFIX, SUFFIX):
    req_parameter_nested = {
        region: {
            district: PREFIX[region] + suffix[-3:]
            for district, suffix in districts.items()
        }
        for region, districts in SUFFIX.items()
    }

    req_parameter = {}
    for region, districts in req_parameter_nested.items():
        if 'ì „ì²´' in districts:
            req_parameter[region] = districts['ì „ì²´']
        for district, code in districts.items():
            req_parameter[district] = code

    req_parameter2 = {
        'ì§€ì—­ë³„': 'domestic',
        'ì§ì—…ë³„': 'job-category',
        'ì—­ì„¸ê¶Œë³„': 'subway',
        'HOT100': 'hot100',
        'í—¤ë“œí—ŒíŒ…': 'headhunting'
    }
    
    return req_parameter, req_parameter2

# ì±„ìš© ì •ë³´ í¬ë¡¤ë§ í•¨ìˆ˜
def crawl_jobs(region_type, page_index, region_code):
    job_link_list = []
    corp_link_list = []
    logo_list = []
    title_list =[]
    job_list = []
    corp_list = []
    local_list = []
    exp_list = []
    grad_list = []
    date_list = []
    badge_list = []
    upload_list = []
    for page in range(1,page_index):
        url = f"https://www.saramin.co.kr/zf_user/jobs/list/{region_type}?page={page}&loc_cd={region_code}&panel_type=&search_optional_item=n&search_done=y&panel_count=y&preview=y"
        print(url)
        req_header = {
            'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'
        }

        res = requests.get(url, headers = req_header)
        res.encoding = 'utf-8'

        
        if res.ok:
            html = res.text
            soup = BeautifulSoup(html, 'html.parser') 
            # CSS ì„ íƒì
            a_tag_list = soup.select("div#default_list_wrap div.list_body div.box_item")
            # <a> íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ìˆœíšŒí•˜ê¸°    
            for a_tag in a_tag_list:
                # ë§í¬
                job_link_dict = {}
                if a_tag.find("div", class_ ="job_tit").find("a", class_ = "str_tit") == None:
                    print(a_tag.find("div", class_ ="job_tit"))
                    job_link_dict['ë§í¬'] = 'NULL'
                else:
                    job_link_dict['ë§í¬'] = "https://www.saramin.co.kr" + a_tag.find("div", class_ ="job_tit").find("a", class_ = "str_tit")['href']
                job_link_list.append(job_link_dict)

                # íšŒì‚¬ ë§í¬
                corp_link_dict = {}
                if a_tag.find("div", class_ ="col company_nm").find("a", class_ = "str_tit") == None:
                    corp_link_dict['íšŒì‚¬ë§í¬'] = 'NULL'
                else:
                    corp_link_dict['íšŒì‚¬ë§í¬'] = "https://www.saramin.co.kr" + a_tag.find("div", class_ ="col company_nm").find("a", class_ = "str_tit")['href']
                corp_link_list.append(corp_link_dict)

                # ë¡œê³ 
                # logo_dict = {}
                # if len(a_tag.select("span.logo img[src*='banner_logo/company/logo_banner/']")) == 0:
                #     logo_dict['ë¡œê³ '] = 'Null'
                # else:
                #     img_url = a_tag.select("span.logo img[src*='banner_logo/company/logo_banner/']")
                #     logo_dict['ë¡œê³ '] = img_url[0]['src']
                # logo_list.append(logo_dict)

                # ì œëª©
                title_dict = {}
                if len(a_tag.find("div", class_ ="col notification_info").find("div", class_ = "job_tit").select("span")) == 0:
                    title_dict['ì œëª©'] = 'Null'
                else:
                    title = a_tag.find("div", class_ ="col notification_info").find("div", class_ = "job_tit").select("span")[0].text
                    title_dict['ì œëª©'] = title
                title_list.append(title_dict)

                # íšŒì‚¬
                corp_dict = {}
                if len(a_tag.find("div", class_ ="col company_nm").find(class_ = "str_tit")) == 0:
                    corp_dict['íšŒì‚¬'] = 'Null'
                else:
                    corp = a_tag.find("div", class_ ="col company_nm").find(class_ = "str_tit").text
                    corp_dict['íšŒì‚¬'] = corp
                corp_list.append(corp_dict)
                clean_corp = []
                for item in corp_list:
                    clean_item = {key: re.sub(r'\s+', ' ', value).strip() for key, value in item.items()}
                    clean_corp.append(clean_item)
                
                # ì§ë¬´
                job_dict = {}
                job = a_tag.select_one('.job_sector')
                if len(job) == 0:
                    job_dict['ì§ë¬´'] = 'Null'
                else:
                    jobs = [span.get_text(strip=True).replace('::before', '').strip() for span in job.find_all('span')]
                    job_dict['ì§ë¬´'] = jobs
                job_list.append(job_dict)
                
                # ì§€ì—­, ê²½ë ¥, í•™ë ¥
                temp = a_tag.find("div", class_ = "col recruit_info")
                local_dict = {}
                exp_dict = {}
                grad_dict = {}
                if len(temp) >= 3:
                    local_dict['ì§€ì—­'] = temp.find("p", class_ = "work_place").text
                    exp_dict['ìš”êµ¬ê²½ë ¥'] = temp.find("p", class_ = "career").text
                    grad_dict['ìµœì†Œí•™ë ¥'] = temp.find("p", class_ = "education").text
                else:
                    local_dict['ì§€ì—­'] = 'NULL'
                    exp_dict['ìš”êµ¬ê²½ë ¥'] = 'NULL'
                    grad_dict['ìµœì†Œí•™ë ¥'] = 'NULL'
                local_list.append(local_dict)
                exp_list.append(exp_dict)
                grad_list.append(grad_dict)

                for region in local_list:
                    if region['ì§€ì—­'].endswith(' ì™¸'):
                        region['ì§€ì—­'] = region['ì§€ì—­'][:-2]

                # ê¸°ê°„
                date_dict = {}
                if len(a_tag.select("span.date")) == 0:
                    date_dict['ê¸°ê°„'] = 'Null'
                else:
                    date = a_tag.select("span.date")[0].text
                    date_dict['ê¸°ê°„'] = date
                date_list.append(date_dict)

                clean_date = []
                for item in date_list:
                    clean_item = {key: re.sub(r'\s+', ' ', value).strip() for key, value in item.items()}
                    clean_date.append(clean_item)

                # ë“±ë¡ì¼ì
                upload_dict = {}
                if len(a_tag.select_one("span.deadlines")) == 0:
                    upload_dict['ë“±ë¡ì¼ì'] = 'Null'
                else:
                    upload = a_tag.select("span.deadlines")[0].text
                    upload_dict['ë“±ë¡ì¼ì'] = upload
                upload_list.append(upload_dict)

                # ë°°ì§€
                badge_dict = {}
                if a_tag.select_one(".job_badge") == None:
                    badge_dict['ë°°ì§€'] = 'Null'
                else:
                    badge = a_tag.select_one(".job_badge").find("span").text
                    badge_dict['ë°°ì§€'] = badge
                badge_list.append(badge_dict)
                clean_badge = []
                for item in badge_list:
                    clean_item = {key: re.sub(r'\s+', ' ', value).strip() for key, value in item.items()}
                    clean_badge.append(clean_item)

        else:
            # ì‘ë‹µ(response)ì´ Error ì´ë©´ status code ì¶œë ¥    
            print(f'ì—ëŸ¬ ì½”ë“œ 1= {res.status_code}')

        
    combined_list = []
    for link, corp_link, title, corp, job, local, exp, grad, date, upload, badge in zip(job_link_list, corp_link_list,title_list, clean_corp, job_list, local_list, exp_list, grad_list, clean_date, upload_list, clean_badge):
        merged_dict = {}
        merged_dict.update(link)
        merged_dict.update(corp_link)
        merged_dict.update(title)
        merged_dict.update(corp)
        merged_dict.update(job)
        merged_dict.update(local)
        merged_dict.update(exp)
        merged_dict.update(grad)
        merged_dict.update(date)
        merged_dict.update(upload)
        merged_dict.update(badge)
        combined_list.append(merged_dict)


    df = pd.DataFrame(combined_list)
    return df
# ë©”ì¸ ì•±
def main():
    st.title("ğŸ” ì‚¬ëŒì¸ ì±„ìš© ì •ë³´ í¬ë¡¤ëŸ¬")
    st.markdown("""
    ì‚¬ëŒì¸ ì‚¬ì´íŠ¸ì—ì„œ ì›í•˜ëŠ” ì§€ì—­ì˜ ì±„ìš© ì •ë³´ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.  
    ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì§€ì—­ ìœ í˜•ê³¼ ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”.
    """)
    
    # ë°ì´í„° ë¡œë“œ
    PREFIX, SUFFIX = load_json_data()
    global req_parameter
    global req_parameter2
    req_parameter, req_parameter2 = parse_data(PREFIX, SUFFIX)

    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("ê²€ìƒ‰ ì„¤ì •")
        
        # ì§€ì—­ ìœ í˜• ì„ íƒ
        region_type_options = {
            'ì§€ì—­ë³„': 'domestic',
            'ì§ì—…ë³„': 'job-category',
            'ì—­ì„¸ê¶Œë³„': 'subway',
            'HOT100': 'hot100',
            'í—¤ë“œí—ŒíŒ…': 'headhunting'
        }
        selected_region_type = st.selectbox(
            "ì§€ì—­ ìœ í˜• ì„ íƒ",
            options=list(region_type_options.keys()),
            index=0
        )
        region_type_code = region_type_options[selected_region_type]
        
        # ì§€ì—­ ì„ íƒ
        if selected_region_type == 'ì§€ì—­ë³„':
            regions = list(req_parameter.keys())
            selected_region = st.selectbox(
                "ì§€ì—­ ì„ íƒ",
                options=regions,
                index=regions.index('ì„œìš¸') if 'ì„œìš¸' in regions else 0
            )
            region_code = req_parameter[selected_region]
        else:
            region_code = ''
        
        # ê²€ìƒ‰ ë²„íŠ¼
        search_button = st.button("ì±„ìš© ì •ë³´ ê°€ì ¸ì˜¤ê¸°", type="primary")
    
    # ë©”ì¸ ì˜ì—­
    if search_button:
        with st.spinner(f"{selected_region if selected_region_type == 'ì§€ì—­ë³„' else selected_region_type} ì±„ìš© ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            df = crawl_jobs(region_type_code, 10, region_code)
            
            if not df.empty:
                st.success(f"ì´ {len(df)}ê°œì˜ ì±„ìš© ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ë°ì´í„° í‘œì‹œ
                st.dataframe(
                    df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        # "ë¡œê³ ": st.column_config.ImageColumn("ë¡œê³ ", help="íšŒì‚¬ ë¡œê³ "),
                        "ë§í¬": st.column_config.LinkColumn("ë§í¬", help="ì±„ìš© ê³µê³  í˜ì´ì§€"),
                    }
                )
                
                # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="CSVë¡œ ë‹¤ìš´ë¡œë“œ",
                    data=csv,
                    file_name=f'saramin_jobs_{selected_region if selected_region_type == "ì§€ì—­ë³„" else selected_region_type}.csv',
                    mime='text/csv'
                )
            else:
                st.warning("í•´ë‹¹ ì§€ì—­ì˜ ì±„ìš© ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
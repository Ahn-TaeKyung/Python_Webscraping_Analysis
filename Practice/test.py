import streamlit as st
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import re
import pandas as pd
import json
from datetime import datetime
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import plotly.express as px  # Plotly Expressë¥¼ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì„í¬íŠ¸
from wordcloud import WordCloud
font_path = 'C:\\windows\\Fonts\\malgun.ttf'
font_prop = fm.FontProperties(fname=font_path).get_name()
matplotlib.rc('font', family=font_prop)
PREFIX = {}
SUFFIX = {}
st.set_page_config(
    page_title="ì‚¬ëŒì¸ ì±„ìš© ì •ë³´ í¬ë¡¤ëŸ¬",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)
tab1, tab2 = st.tabs(["ì±„ìš©ê³µê³ ", "ë¶„ì„"])
# ì‚°ì—…êµ° ì¹´í…Œê³ ë¦¬ì™€ ê° ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤í•‘
industry_keywords = {
    "ì„œë¹„ìŠ¤ì—…": ["ê³ ê° ì„œë¹„ìŠ¤", "íŒë§¤", "ì„œë¹„ìŠ¤", "ì˜ì—…", "ìƒë‹´", "CS", "A/S"],
    "ì œì¡°/í™”í•™": ["ì œì¡°", "ìƒì‚°", "í™”í•™", "ê¸°ê³„", "ê³µì¥", "í’ˆì§ˆ", "ìƒì‚°ê´€ë¦¬"],
    "ì˜ë£Œ/ì œì•½/ë³µì§€": ["ì˜ë£Œ", "ê°„í˜¸", "ì•½ì‚¬", "ì˜ì‚¬", "ì œì•½", "ë³µì§€", "ê±´ê°•", "ë³‘ì›", "ë³´í—˜"],
    "ìœ í†µ/ë¬´ì—­/ìš´ì†¡": ["ìœ í†µ", "ë¬¼ë¥˜", "ìš´ì†¡", "ë¬´ì—­", "ìˆ˜ì¶œ", "ìˆ˜ì…", "ì°½ê³ "],
    "êµìœ¡ì—…": ["êµì‚¬", "êµìœ¡", "í•™ì›", "ê°•ì‚¬", "í•™ìŠµ", "í•™ìƒ", "êµìœ¡ê¸°ê´€"],
    "ê±´ì„¤ì—…": ["ê±´ì„¤", "í† ëª©", "ê±´ì¶•", "ì‹œì„¤", "ê±´ì¶•ì‚¬", "ê±´ì„¤í˜„ì¥", "ì„¤ê³„"],
    "IT/ì›¹/í†µì‹ ": ["ê°œë°œ", "í”„ë¡œê·¸ë˜ë°", "ì†Œí”„íŠ¸ì›¨ì–´", "í•˜ë“œì›¨ì–´", "ì›¹", "í†µì‹ ", "IT", "ë„¤íŠ¸ì›Œí¬", "C", "Java", "AI", "API", "Android", "DB", ],
    "ë¯¸ë””ì–´/ë””ìì¸": ["ë””ìì¸", "ê·¸ë˜í”½", "ì˜ìƒ", "ë¯¸ë””ì–´", "í™ë³´", "ê´‘ê³ ", "ë§ˆì¼€íŒ…", "ì•„íŠ¸", "ART"],
    "ì€í–‰/ê¸ˆìœµì—…": ["ì€í–‰", "ê¸ˆìœµ", "íšŒê³„", "ì„¸ë¬´", "íˆ¬ì", "ëŒ€ì¶œ", "ìì‚°ê´€ë¦¬"],
    "ê¸°ê´€/í˜‘íšŒ": ["ê¸°ê´€", "í˜‘íšŒ", "NGO", "ì •ë¶€", "ë¹„ì˜ë¦¬", "í–‰ì •", "ì‚¬íšŒë³µì§€"]
}

# âœ… ì‚°ì—…êµ° ì´ë¦„-ì½”ë“œ ë§¤í•‘
industry_map = {
    "ì„œë¹„ìŠ¤ì—…": 100,
    "ì œì¡°/í™”í•™": 200,
    "ì˜ë£Œ/ì œì•½/ë³µì§€": 300,
    "ìœ í†µ/ë¬´ì—­/ìš´ì†¡": 400,
    "êµìœ¡ì—…": 500,
    "ê±´ì„¤ì—…": 600,
    "IT/ì›¹/í†µì‹ ": 700,
    "ë¯¸ë””ì–´/ë””ìì¸": 800,
    "ì€í–‰/ê¸ˆìœµì—…": 900,
    "ê¸°ê´€/í˜‘íšŒ": 1000
}
# ì¡í”Œë˜ë‹› ì§€ì—­ ë§¤í•‘
score_region = {
    "ì„œìš¸" : 1,
    "ê²½ê¸°" : 2,
    "ì¸ì²œ" : 3,
    "ë¶€ì‚°" : 4,
    "ëŒ€êµ¬" : 5,
    "ëŒ€ì „" : 6,
    "ê´‘ì£¼" : 7,
    "ìš¸ì‚°" : 8,
    "ì„¸ì¢…" : 9,
    "ê°•ì›" : 10,
    "ê²½ë‚¨" : 11,
    "ê²½ë¶" : 12,
    "ì „ë‚¨" : 13,
    "ì „ë¶" : 14,
    "ì¶©ë‚¨" : 15,
    "ì¶©ë¶" : 16,
    "ì œì£¼" : 17
}

# ì§ë¬´ì— ë§ëŠ” ì‚°ì—…êµ° ë§¤í•‘ í•¨ìˆ˜
def map_job_to_industry(job):
    for industry, keywords in industry_keywords.items():
        for keyword in keywords:
            if keyword in job:
                return industry
    return "ê¸°íƒ€"  # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°íƒ€ë¡œ ë¶„ë¥˜

@st.cache_data
def load_json_data():
    file_path = 'data/'
    with open(file_path + 'PREFIX.json', 'r', encoding='utf-8') as f:
        PREFIX = json.load(f)
    with open(file_path + 'SUFFIX.json', 'r', encoding='utf-8') as f:
        SUFFIX = json.load(f)
    return PREFIX, SUFFIX

@st.cache_data
def parse_data(PREFIX, SUFFIX):
    req_parameter = {}
    region_subregion_map = {}

    for region, subregions in SUFFIX.items():
        region_code_prefix = PREFIX.get(region)
        if not region_code_prefix:
            continue

        region_subregion_map[region] = list(subregions.keys())
        for subregion, suffix_code in subregions.items():
            key = f"{region} {subregion}"
            req_parameter[key] = region_code_prefix + suffix_code

    return req_parameter, region_subregion_map

def parse_location_input(selected_region, selected_subregions):
    region_codes = []
    # print(selected_subregions)
    # if selected_subregions == ['ì „ì²´']:
    #     print(selected_region)
    #     selected_region = selected_region[0]
    #     print(selected_region)

    
    for district in selected_subregions:
        key = f"{selected_region} {district}"
        code = req_parameter.get(key)

        if code:
            region_codes.append(code)
        else:
            st.warning(f"âš ï¸ ì§€ì—­ ì½”ë“œ ì—†ìŒ: '{key}'")
    
    return "%2C".join(region_codes)

def split_info(text):
    if not isinstance(text, str):
        return pd.Series([None, None])
    parts = re.split(r'\s*Â·\s*', text)
    if len(parts) >= 2:
        exp = ' Â· '.join(parts[:-1]).strip()
        job_type = re.sub(r'\s*ì™¸$', '', parts[-1].strip())
        return pd.Series([exp, job_type])
    else:
        return pd.Series([text.strip(), None])
    
def normalize_experience(exp):
    if not isinstance(exp, str) or not exp.strip():
        return "ì •ë³´ ì—†ìŒ"

    exp = exp.strip()
    if 'ì‹ ì…' in exp and 'ê²½ë ¥' in exp:
        return 'ì‹ ì…/ê²½ë ¥'
    elif 'ì‹ ì…' in exp:
        return 'ì‹ ì…'
    elif 'ê²½ë ¥ë¬´ê´€' in exp or 'ë…„ìˆ˜ë¬´ê´€' in exp:
        return 'ê²½ë ¥ë¬´ê´€'
    elif re.match(r'\d+\s*~\s*\d+ë…„', exp):
        return exp.replace(' ', '')
    elif re.match(r'\d+ë…„\s*ì´ìƒ', exp):
        return exp
    elif re.match(r'\d+ë…„\s*ì´í•˜', exp):
        return exp
    elif exp == 'ê²½ë ¥':
        return 'ê²½ë ¥'
    return "ì •ë³´ ì—†ìŒ"

def normalize_education(education):
    if not isinstance(education, str):
        return None
    return education.replace('â†‘', '').strip()

def calculate_remaining_days(deadline):
    if not isinstance(deadline, str) or "ì±„ìš©ì‹œ" in deadline or "ë§ˆê°" in deadline:
        return "ê¸°ê°„ ì—†ìŒ"

    if deadline.startswith("D-"):
        try:
            remaining_days = int(deadline[2:])
            if remaining_days < 0:
                return "ë§ˆê°"
            return f"{remaining_days}ì¼ ë‚¨ìŒ"
        except ValueError:
            return "ê¸°ê°„ ì—†ìŒ"

    if deadline.startswith("~"):
        try:
            match = re.search(r'~(\d{2})\.(\d{2})', deadline)
            if match:
                month, day = int(match.group(1)), int(match.group(2))
                current_year = datetime.now().year
                deadline_date = datetime(current_year, month, day)
                remaining_days = (deadline_date - datetime.now()).days
                if remaining_days < 0:
                    return "ë§ˆê°"
                return f"{remaining_days}ì¼ ë‚¨ìŒ"
            return "ê¸°ê°„ ì—†ìŒ"
        except ValueError:
            return "ê¸°ê°„ ì—†ìŒ"

    if "ì‹œ ë§ˆê°" in deadline:
        try:
            match = re.search(r'(\d{1,2})ì‹œ', deadline)
            if match:
                hour = int(match.group(1))
                now = datetime.now()
                deadline_time = now.replace(hour=hour, minute=0, second=0, microsecond=0)
                if deadline_time < now:
                    return "ë§ˆê°"
                remaining_seconds = (deadline_time - now).total_seconds()
                remaining_hours = remaining_seconds // 3600
                return f"{int(remaining_hours)}ì‹œê°„ ë‚¨ìŒ"
            return "ê¸°ê°„ ì—†ìŒ"
        except ValueError:
            return "ê¸°ê°„ ì—†ìŒ"

    try:
        deadline_date = datetime.strptime(deadline, "%Y-%m-%d")
        remaining_days = (deadline_date - datetime.now()).days
        if remaining_days < 0:
            return "ë§ˆê°"
        return f"{remaining_days}ì¼ ë‚¨ìŒ"
    except ValueError:
        return "ê¸°ê°„ ì—†ìŒ"

def crawl_jobs(page_index, selected_region, selected_subregions):
    results = []
    loc_cd_param = parse_location_input(selected_region, selected_subregions)
    for page in range(1, page_index + 1):
        url = (
            f"https://www.saramin.co.kr/zf_user/jobs/list/domestic"
            f"?page={page}&loc_cd={loc_cd_param}&search_done=y&preview=y"
        )
        headers = {'user-agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        if not res.ok:
            st.error(f"ìš”ì²­ ì‹¤íŒ¨: {res.status_code}")
            continue

        soup = BeautifulSoup(res.text, 'html.parser')
        job_items = soup.select("div#default_list_wrap div.list_body div.box_item")

        for item in job_items:
            def extract_text(selector, default='Null'):
                tag = item.select_one(selector)
                return tag.text.strip() if tag else default

            def extract_href(selector, prefix="https://www.saramin.co.kr"):
                tag = item.select_one(selector)
                return prefix + tag['href'] if tag and 'href' in tag.attrs else 'NULL'

            results.append({
                'ì œëª©': extract_text("div.job_tit span"),
                'ì§ë¬´': [tag.text.strip() for tag in item.select(".job_sector span") if tag.text.strip()],
                'ì§€ì—­': extract_text(".recruit_info .work_place").rstrip(' ì™¸'),
                'ìš”êµ¬ê²½ë ¥': extract_text(".recruit_info .career"),
                'ìµœì†Œí•™ë ¥': extract_text(".recruit_info .education"),
                'ê¸°ê°„': extract_text("span.date"),
                'ë§í¬': extract_href("div.job_tit a.str_tit"),
                'íšŒì‚¬': extract_text("div.col.company_nm .str_tit"),
                'íšŒì‚¬ë§í¬': extract_href("div.col.company_nm a.str_tit"),
                'ë“±ë¡ì¼ì': extract_text("span.deadlines"),
                'ë°°ì§€': extract_text(".job_badge span")
            })

    df = pd.DataFrame(results)
    if not df.empty:
        df[['ìš”êµ¬ê²½ë ¥_raw', 'ê³„ì•½ì¢…ë¥˜']] = df['ìš”êµ¬ê²½ë ¥'].apply(split_info)
        df['ìš”êµ¬ê²½ë ¥'] = df['ìš”êµ¬ê²½ë ¥_raw'].apply(normalize_experience)
        df['ìµœì†Œí•™ë ¥'] = df['ìµœì†Œí•™ë ¥'].apply(normalize_education)
        df['ë‚¨ì€ê¸°ê°„'] = df['ê¸°ê°„'].apply(calculate_remaining_days)
        df.drop(columns=['ìš”êµ¬ê²½ë ¥_raw'], inplace=True)
        df.dropna(axis=0, inplace=True)
    return df

def filter_by_experience(df, exp_input, include_general):
    
    def parse_year_range(exp_text):
        match = re.search(r'(\d+)\s*~\s*(\d+)', exp_text)
        if match:
            return int(match.group(1)), int(match.group(2))
        match = re.search(r'(\d+)\s*ë…„\s*ì´ìƒ', exp_text)
        if match:
            return int(match.group(1)), float('inf')
        match = re.search(r'(\d+)\s*ë…„\s*ì´í•˜', exp_text)
        if match:
            return 0, int(match.group(1))
        match = re.search(r'ê²½ë ¥\s*(\d+)\s*ë…„', exp_text)
        if match:
            return int(match.group(1)), int(match.group(1))
        return None, None

    general_conditions = ['ì‹ ì…', 'ì‹ ì…/ê²½ë ¥', 'ê²½ë ¥ë¬´ê´€', 'ì •ë³´ ì—†ìŒ']

    try:
        exp_val = int(re.search(r'\d+', exp_input.strip()).group()) if exp_input.strip() else None
    except AttributeError:
        st.warning("âš ï¸ ê²½ë ¥ ì…ë ¥ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ê¸°ë³¸ í•„í„°ë§Œ ì ìš©í•©ë‹ˆë‹¤.")
        return df[df['ìš”êµ¬ê²½ë ¥'].isin(general_conditions) if include_general else []]

    filtered_rows = []

    for _, row in df.iterrows():
        exp = row['ìš”êµ¬ê²½ë ¥']
        min_exp, max_exp = parse_year_range(exp)

        # Include general conditions if 'include_general' is True
        if include_general and exp in general_conditions:
            filtered_rows.append(row)
        # Add rows matching the experience range
        if min_exp is not None and exp_val is not None and exp_val >= min_exp:
            filtered_rows.append(row)

    # Filtered DataFrame
    filtered_df = pd.DataFrame(filtered_rows)

    return filtered_df
    
def star_score(job_code, selected_region):
    # âœ… í¬ë¡¬ ì˜µì…˜ ì„¤ì •
    options = Options()
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)")

    # âœ… ë“œë¼ì´ë²„ ì‹¤í–‰
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # âœ… URL ì„¤ì •
    base_url = f"https://www.jobplanet.co.kr/companies?sort_by=review_compensation_cache&industry_id={job_code}&city_id={score_region[selected_region]}"

    companies = []
    page = 1

    while True:
        url = f"{base_url}&page={page}"
        driver.get(url)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        company_blocks = soup.select("div.section_wrap div.section_group section.company")
        # if page == 10:
        #     break
        if not company_blocks:
            print(f"â— í˜ì´ì§€ {page}ì— ë” ì´ìƒ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ë§ ì¢…ë£Œ.")
            break

        for item in company_blocks:
            name_tag = item.select_one("dt.us_titb_l3 a")
            rating_tag = item.select_one("div.us_star_m div.star_score")

            if name_tag and rating_tag:
                name = name_tag.get_text(strip=True)
                rating_style = rating_tag.get("style", "")
                try:
                    width_pct = float(rating_style.replace("width:", "").replace("%", "").strip())
                    rating = round(width_pct / 20, 1)
                except:
                    rating = None

                companies.append({
                    "íšŒì‚¬ëª…": name,
                    "í‰ì ": rating
                })

        print(f"âœ… {page}í˜ì´ì§€ ì™„ë£Œ, ëˆ„ì  ê¸°ì—… ìˆ˜: {len(companies)}")
        page += 1

    df = pd.DataFrame(companies)
    driver.quit();

    return df


def visualize_experience_distribution():
    st.subheader("ê²½ë ¥ ìš”êµ¬ì‚¬í•­ ë¶„í¬")
    if st.session_state.all_jobs.empty:
        st.info("ê³µê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
        return

    # ë°ì´í„° ì¤€ë¹„
    experience_counts = st.session_state.all_jobs['ìš”êµ¬ê²½ë ¥'].value_counts().reset_index()
    experience_counts.columns = ['ìš”êµ¬ê²½ë ¥', 'ê³µê³ ìˆ˜']

    # ì›í˜• ê·¸ë˜í”„ ìƒì„±
    fig = px.pie(
        experience_counts,
        names='ìš”êµ¬ê²½ë ¥',
        values='ê³µê³ ìˆ˜',
        title="ê²½ë ¥ ìš”êµ¬ì‚¬í•­ ë¶„í¬",
        hole=0.3  # ë„ë„› í˜•íƒœë¡œ ë³€ê²½
    )

    # ì›í˜• ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì • (ë³µêµ¬)
    fig.update_traces(
        textinfo='percent+label',  # í¼ì„¼íŠ¸ì™€ ë ˆì´ë¸” í‘œì‹œ
        textfont_size=14,  # í°íŠ¸ í¬ê¸°
        insidetextorientation='radial',  # í…ìŠ¤íŠ¸ ë°©í–¥
        marker=dict(line=dict(width=0))  # êµ¬ë¶„ì„  ì œê±°
    )

    # ê·¸ë˜í”„ ì¶œë ¥
    st.plotly_chart(fig, use_container_width=True)

def visualize_education_distribution():
    st.subheader("ìµœì†Œ í•™ë ¥ ìš”êµ¬ ë¶„í¬")
    if st.session_state.all_jobs.empty:
        st.info("ê³µê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
        return

    # ë°ì´í„° ì¤€ë¹„
    education_counts = st.session_state.all_jobs['ìµœì†Œí•™ë ¥'].value_counts().reset_index()
    education_counts.columns = ['ìµœì†Œí•™ë ¥', 'ê³µê³ ìˆ˜']

    # ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±
    fig = px.bar(
        education_counts,
        x='ìµœì†Œí•™ë ¥',
        y='ê³µê³ ìˆ˜',
        title="ìµœì†Œ í•™ë ¥ ìš”êµ¬ ë¶„í¬"
    )

    # ê·¸ë˜í”„ ì¶œë ¥
    st.plotly_chart(fig, use_container_width=True)

def main_tab():
    st.title(":mag: ì‚¬ëŒì¸ ì±„ìš© ì •ë³´ í¬ë¡¤ëŸ¬")
    st.markdown("""ì‚¬ëŒì¸ ì‚¬ì´íŠ¸ì—ì„œ ì›í•˜ëŠ” ì§€ì—­ì˜ ì±„ìš© ì •ë³´ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤.""")

    PREFIX, SUFFIX = load_json_data()
    global req_parameter
    global region_subregion_map
    req_parameter, region_subregion_map = parse_data(PREFIX, SUFFIX)

    if "all_jobs" not in st.session_state:
        st.session_state.all_jobs = pd.DataFrame()
    if "filtered_jobs" not in st.session_state:
        st.session_state.filtered_jobs = pd.DataFrame()
    if "favorites" not in st.session_state:
        st.session_state.favorites = pd.DataFrame()
    if "show_favorites" not in st.session_state:
        st.session_state.show_favorites = False
    if "current_page" not in st.session_state:
        st.session_state.current_page = 1
    if "comp_score" not in st.session_state:
        st.session_state.comp_score = pd.DataFrame()

    if st.button("â­ ë‚˜ì˜ ì¦ê²¨ì°¾ê¸°"):
        st.session_state.show_favorites = not st.session_state.show_favorites

    if st.session_state.show_favorites:
        st.header("ë‚˜ì˜ ì¦ê²¨ì°¾ê¸°")
        if st.session_state.favorites.empty:
            st.info("ì¦ê²¨ì°¾ê¸° ëª©ë¡ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(st.session_state.favorites, use_container_width=True)

    with st.sidebar:
        st.header("ëŒ€ë¶„ë¥˜ ì§€ì—­ ì„ íƒ")
        selected_region = st.selectbox("ëŒ€ë¶„ë¥˜ ì§€ì—­", list(region_subregion_map.keys()))

        st.header("ì„¸ë¶€ ì§€ì—­ ì„ íƒ (í•„ìˆ˜)")
        subregions = region_subregion_map[selected_region]
        # subregions = set()
        # for sub_region in selected_region:
        #     for temp in region_subregion_map[sub_region]:
        #         subregions.add(temp) 
        selected_subregions = st.multiselect("ì„¸ë¶€ ì§€ì—­", subregions)

        if st.button("ê³µê³  ê°€ì ¸ì˜¤ê¸°"):
            if not selected_subregions:
                st.warning("ğŸš¨ ì„¸ë¶€ ì§€ì—­ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
                st.stop()

            with st.spinner("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                st.session_state.all_jobs = crawl_jobs(10, selected_region, selected_subregions)
                st.session_state.filtered_jobs = st.session_state.all_jobs.copy()
                st.session_state.current_page = 1
                st.success(f"{len(st.session_state.all_jobs)}ê°œì˜ ê³µê³ ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤!")

        if not st.session_state.all_jobs.empty:
            st.header("í•„í„°")
            unique_jobs = sorted(set(
                job for job_list in st.session_state.all_jobs['ì§ë¬´'].dropna() if isinstance(job_list, list) for job in job_list
            ))
            selected_jobs = st.multiselect("ì§ë¬´ ì„ íƒ", unique_jobs)

            filtered_df = st.session_state.all_jobs.copy()
            if selected_jobs:
                filtered_df = filtered_df[filtered_df['ì§ë¬´'].apply(lambda x: any(job in x for job in selected_jobs))]
                if st.button("í‰ì  ê°€ì ¸ì˜¤ê¸°"):
                    job_industry_mapping = {job: map_job_to_industry(job) for job in selected_jobs}
                    industry_name = list(job_industry_mapping.values())[0]
                    print(industry_name)
                    industry_code = industry_map.get(industry_name)
                    
                    st.session_state.comp_score = star_score(industry_code, selected_region)
            comp_input = st.text_input("í‰ì ì„ í™•ì¸í•  ê¸°ì—…ì„ ì…ë ¥í•˜ì„¸ìš”\.", "")
            if comp_input:
                matched = st.session_state.comp_score[
                    st.session_state.comp_score['íšŒì‚¬ëª…'].str.contains(comp_input, na=False)
                ]
                if matched.empty:
                    st.info("í•´ë‹¹ ê¸°ì—…ì— ëŒ€í•œ í‰ì  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.dataframe(matched, use_container_width=True)
            st.header("ìš”êµ¬ ê²½ë ¥ í•„í„°")
            include_general = st.checkbox("ê²½ë ¥ë¬´ê´€ í¬í•¨", value=True)
            experience_input = st.text_input("ê²½ë ¥ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 0, ìˆ«ì ë˜ëŠ” ì‹ ì…)", "")

            if experience_input or include_general:
                filtered_df = filter_by_experience(filtered_df, experience_input, include_general)
                if filtered_df.empty:
                    st.warning("í•´ë‹¹ ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"{len(filtered_df)}ê°œì˜ ê³µê³ ê°€ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤.")

            st.header("í•™ë ¥ í•„í„°")
            if 'ìµœì†Œí•™ë ¥' not in filtered_df.columns:
                st.warning("ğŸš« 'í•™ë ¥' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                unique_educations = filtered_df['ìµœì†Œí•™ë ¥'].dropna().unique()
                selected_educations = st.multiselect("í•™ë ¥ì„ ì„ íƒí•˜ì„¸ìš”", ["ì „ì²´"] + list(unique_educations))
                filtered_df = filter_by_education(filtered_df, selected_educations)

            st.session_state.filtered_jobs = filtered_df

    if not st.session_state.filtered_jobs.empty:
        st.header("ê²€ìƒ‰ ê²°ê³¼")

        jobs_per_page = 20
        total_jobs = len(st.session_state.filtered_jobs)
        total_pages = (total_jobs + jobs_per_page - 1) // jobs_per_page

        start_idx = (st.session_state.current_page - 1) * jobs_per_page
        end_idx = start_idx + jobs_per_page
        page_jobs = st.session_state.filtered_jobs.iloc[start_idx:end_idx]

        for idx, row in page_jobs.iterrows():
            with st.container():
                st.markdown("---")
                col1, col2 = st.columns([9, 1])

                with col1:
                    st.markdown(f"### **[{row['ì œëª©']}]({row['ë§í¬']})**")
                    st.markdown(f"- **íšŒì‚¬**: [{row['íšŒì‚¬']}]({row['íšŒì‚¬ë§í¬']})")
                    st.markdown(f"- **ì§ë¬´**: {', '.join(row['ì§ë¬´'])}")  # ì§ë¬´ ìˆ˜ì •ëœ ë¶€ë¶„
                    st.markdown(f"- **ì§€ì—­**: {row['ì§€ì—­']}")
                    st.markdown(f"- **ê²½ë ¥**: {row['ìš”êµ¬ê²½ë ¥']}")
                    st.markdown(f"- **í•™ë ¥**: {row['ìµœì†Œí•™ë ¥']}")

                    if "ë§ˆê°" in row['ë‚¨ì€ê¸°ê°„']:
                        st.markdown(f"- **ë‚¨ì€ ê¸°ê°„**: <span style='color:red'>{row['ë‚¨ì€ê¸°ê°„']}</span>", unsafe_allow_html=True)
                    elif "ì‹œê°„ ë‚¨ìŒ" in row['ë‚¨ì€ê¸°ê°„']:
                        st.markdown(f"- **ë‚¨ì€ ê¸°ê°„**: <span style='color:orange'>{row['ë‚¨ì€ê¸°ê°„']}</span>", unsafe_allow_html=True)
                    else:
                        st.markdown(f"- **ë‚¨ì€ ê¸°ê°„**: <span style='color:green'>{row['ë‚¨ì€ê¸°ê°„']}</span>", unsafe_allow_html=True)

                with col2:
                    if st.button("â­", key=f"fav_{idx}"):
                        if not st.session_state.favorites.empty and row.to_dict() in st.session_state.favorites.to_dict('records'):
                            st.session_state.favorites = st.session_state.favorites[st.session_state.favorites['ì œëª©'] != row['ì œëª©']]
                            st.warning("ì¦ê²¨ì°¾ê¸°ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.session_state.favorites = pd.concat([st.session_state.favorites, pd.DataFrame([row])], ignore_index=True)
                            st.success("ì¦ê²¨ì°¾ê¸°ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")

        col1, col2, col3 = st.columns(3)
        if st.session_state.current_page > 1:
            if col1.button("ì´ì „ í˜ì´ì§€"):
                st.session_state.current_page -= 1
        col2.write(f"í˜ì´ì§€ {st.session_state.current_page} / {total_pages}")
        if st.session_state.current_page < total_pages:
            if col3.button("ë‹¤ìŒ í˜ì´ì§€"):
                st.session_state.current_page += 1

def visualize_job_distribution():
    st.subheader("ì§€ì—­ë³„ ì§ë¬´ ë¶„í¬ (íŠ¸ë¦¬ë§µ)")
    if st.session_state.all_jobs.empty:
        st.info("ê³µê³  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
        return

    # ë°ì´í„° ì¤€ë¹„
    job_region_df = st.session_state.all_jobs.explode('ì§ë¬´')[['ì§€ì—­', 'ì§ë¬´']]
    job_region_counts = job_region_df.groupby(['ì§€ì—­', 'ì§ë¬´']).size().reset_index(name='ê³µê³ ìˆ˜')

    # íŠ¸ë¦¬ë§µ ìƒì„±
    fig = px.treemap(
        job_region_counts,
        path=['ì§€ì—­', 'ì§ë¬´'],  # ê³„ì¸µì  êµ¬ì¡°: ì§€ì—­ > ì§ë¬´
        values='ê³µê³ ìˆ˜',
        title="ì§€ì—­ë³„ ì§ë¬´ ë¶„í¬ (íŠ¸ë¦¬ë§µ)"
    )

    # íŠ¸ë¦¬ë§µ ì¶œë ¥
    st.plotly_chart(fig, use_container_width=True)

def visual_word_cloud():
    dev_df = st.session_state.all_jobs[st.session_state.all_jobs['ì œëª©'].str.contains('ê°œë°œ', na=False)]
    df_exploded = dev_df.explode('ì§ë¬´')
    job_counts = df_exploded['ì§ë¬´'].value_counts()

    wordcloud = WordCloud(font_path=font_path, width=800, height=400, background_color='white', colormap='viridis')
    wordcloud.generate_from_frequencies(job_counts.to_dict())

    plt.figure(figsize=(18, 20))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')

    st.pyplot(plt)
    plt.clf()  # Streamlitì—ì„œ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥í•  ë•Œ ì´ì „ ê·¸ë˜í”„ í´ë¦¬ì–´

# ì§€ì—­ë³„ ê³µê³ ìˆ˜ ë¶„ì„ì„ ì‹œê°í™” í•¨ìˆ˜ë¡œ ë¶„ë¦¬
def visual_chart_count():
    
    
    # ì§€ì—­ë³„ ì±„ìš© ê³µê³ ìˆ˜ ì§‘ê³„
    job_counts = st.session_state.all_jobs['ì§€ì—­'].value_counts().reset_index()
    job_counts.columns = ['ì§€ì—­', 'ê³µê³ ìˆ˜']

    # ë§‰ëŒ€ ê·¸ë˜í”„ ì¶œë ¥ (í‘œ ìœ„ë¡œ ì´ë™)
    st.subheader("ì§€ì—­ë³„ ì±„ìš© ê³µê³ ìˆ˜ ì‹œê°í™”")
    fig = px.bar(
        job_counts,
        x='ì§€ì—­',
        y='ê³µê³ ìˆ˜',
        title='ì§€ì—­ë³„ ì±„ìš© ê³µê³ ìˆ˜',
        color='ê³µê³ ìˆ˜',  # ê³µê³ ìˆ˜ì— ë”°ë¼ ìƒ‰ìƒ ë³€í™˜
        labels={'ì§€ì—­': 'ì§€ì—­', 'ê³µê³ ìˆ˜': 'ì±„ìš© ê³µê³ ìˆ˜'},
        text='ê³µê³ ìˆ˜'  # ë§‰ëŒ€ ìœ„ì— ê³µê³ ìˆ˜ í‘œì‹œ
    )
    fig.update_traces(
        texttemplate='%{text}',  # í…ìŠ¤íŠ¸ í˜•ì‹
        textposition='outside',  # í…ìŠ¤íŠ¸ ìœ„ì¹˜
        marker=dict(line=dict(color='black', width=1.5))  # ë§‰ëŒ€ í…Œë‘ë¦¬ ì¶”ê°€
    )
    fig.update_layout(
        title=dict(font=dict(size=20), x=0.5),  # ì œëª© ê°€ìš´ë° ì •ë ¬
        xaxis=dict(title='ì§€ì—­', tickangle=45),  # Xì¶• ë ˆì´ë¸” ê°ë„ ì¡°ì •
        yaxis=dict(title='ì±„ìš© ê³µê³ ìˆ˜', gridcolor='lightgray'),  # Yì¶• ê·¸ë¦¬ë“œ ìƒ‰ìƒ ì¡°ì •
        plot_bgcolor='white'  # ë°°ê²½ ìƒ‰ìƒ í°ìƒ‰
    )
    st.plotly_chart(fig, use_container_width=True)

    # í‘œ ì¶œë ¥ (ë§‰ëŒ€ ê·¸ë˜í”„ ì•„ë˜ë¡œ ì´ë™)
    st.subheader("ì§€ì—­ë³„ ì±„ìš© ê³µê³ ìˆ˜")
    st.dataframe(job_counts, use_container_width=True)

def visual_chart_exp():
    plt.figure(figsize=(10, 6))
    plt.figure(figsize=(10, 6))
    
#     # 'ê°œë°œ' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê³µê³ ë§Œ í•„í„°ë§
    dev_df = st.session_state.all_jobs[st.session_state.all_jobs['ì œëª©'].str.contains('ê°œë°œ', na=False)]
    
    # ì¹´ìš´íŠ¸ í”Œë¡¯
    sns.countplot(data=dev_df, x='ìš”êµ¬ê²½ë ¥', order=dev_df['ìš”êµ¬ê²½ë ¥'].value_counts().index)
    plt.title('ê°œë°œì ìš”êµ¬ ê²½ë ¥ ë¶„í¬')
    plt.xlabel('ìš”êµ¬ ê²½ë ¥')
    plt.ylabel('ê³µê³  ìˆ˜')
    plt.xticks(rotation=45)
    plt.tight_layout()
    
    # Streamlitì— ì¶œë ¥
    st.pyplot(plt)
    plt.clf()  # Streamlitì—ì„œ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥í•  ë•Œ ì´ì „ ê·¸ë˜í”„ í´ë¦¬ì–´

def visual_piechart():
    contract_counts = st.session_state.all_jobs['ê³„ì•½ì¢…ë¥˜'].value_counts()

    fig = px.pie(
        names=contract_counts.index,
        values=contract_counts.values,
        title='ê³„ì•½ ì¢…ë¥˜ë³„ ê³µê³  ìˆ˜ ë¶„í¬',
        hole=0.3
    )

    fig.update_traces(
        textinfo='percent+label',
        textposition='outside',        # ë°”ê¹¥ì— ë¼ë²¨ í‘œì‹œ
        rotation=120,                  # ì‹œì‘ ê°ë„ ì„¤ì •
        pull=[0.05] * len(contract_counts),  # í•­ëª© ì‚´ì§ ë¶„ë¦¬
    )

    fig.update_layout(
        showlegend=True,
        title=dict(font=dict(size=20), x=0),
        uniformtext_minsize=10,        # ë„ˆë¬´ ì‘ì€ í…ìŠ¤íŠ¸ëŠ” ìƒëµ
        uniformtext_mode='hide',
        height=600,                    # ì°¨íŠ¸ í¬ê¸° í‚¤ìš°ê¸°
        width=800,
    )

    st.plotly_chart(fig, use_container_width=True)


def visual_tab():
    # ğŸ“Š ë¶„ì„ íƒ­ ë‚´ìš©
    st.title("ğŸ“Š ì§€ì—­ë³„ ì±„ìš© ê³µê³ ìˆ˜ ë¶„ì„")
    if st.session_state.all_jobs.empty:
        st.warning("ë¨¼ì € 'ê³µê³  ê°€ì ¸ì˜¤ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.")
        return
    # ì‹œê°í™” í•¨ìˆ˜ í˜¸ì¶œ
    visual_chart_count()
    visual_chart_exp()
    visual_piechart()
    visual_word_cloud()

    visualize_job_distribution()
    visualize_experience_distribution()
    visualize_education_distribution()
    


def main():
    with tab1:
        main_tab()
    with tab2:
        visual_tab()
# ìµœì†Œ í•™ë ¥ í•„í„° í•¨ìˆ˜ ì¶”ê°€
def filter_by_education(df, selected_educations):
    """
    Filters the DataFrame based on the selected education levels.
    If "ì „ì²´" is selected, no filtering is applied.
    """
    if not isinstance(selected_educations, (list, pd.Series)):
        selected_educations = [selected_educations]
    
    # "ì „ì²´" ì„ íƒ ì‹œ í•„í„°ë§ ì—†ì´ ë°˜í™˜
    if not selected_educations or "ì „ì²´" in selected_educations:
        return df
    # ì„ íƒëœ í•™ë ¥ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
    return df[df['ìµœì†Œí•™ë ¥'].isin(selected_educations)]

if __name__ == "__main__":
    main()